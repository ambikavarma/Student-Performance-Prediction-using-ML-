# -*- coding: utf-8 -*-
"""STUDENT PERFORMANCE PREDICTION

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W6wq5HWEnGPbYfiINjZHq_WDUHvDw5Ac
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
data = pd.read_csv("StressLevelDataset.csv")

data.head()

data.tail()

data.info()

data.describe()

data.isnull().sum()

# adding new column through feature engineering
data.insert(0, 'student_id', range(100, 100 + len(data)))
data

column_names = data.columns
print(column_names)

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'data' is your DataFrame
# If you have missing libraries, you can install them using: !pip install seaborn matplotlib

# Select numerical columns for which you want to check outliers
numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns

# Create boxplots for each numerical column
plt.figure(figsize=(20, 12))
for column in numerical_columns:
    plt.subplot(5, 10, numerical_columns.get_loc(column) + 1)  # Adjust the subplot layout based on the number of numerical columns
    sns.boxplot(x=data[column])
    plt.title(f'{column}')

plt.tight_layout()
plt.show()

from sklearn.preprocessing import StandardScaler

# Features to normalize
features_to_normalize = ['anxiety_level', 'self_esteem', 'depression', 'blood_pressure', 'social_support']

# Create a StandardScaler
scaler = StandardScaler()

# Normalize the selected features
data[features_to_normalize] = scaler.fit_transform(data[features_to_normalize])

# Verify the changes
print(data[features_to_normalize])

# Create boxplots for each numerical column after normalization
plt.figure(figsize=(20, 12))
for column in numerical_columns:
    plt.subplot(5, 10, numerical_columns.get_loc(column) + 1)
    sns.boxplot(x=data[column])
    plt.title(f'{column}')

plt.tight_layout()
plt.show()

data.head()

#noise level
outliers = []

def detect_outliers_iqr(data):
    # Convert data to numeric type
    data = np.asarray(data, dtype=np.float64)

    data = sorted(data)
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    IQR = q3 - q1
    lwr_bound = q1 - (1.5 * IQR)
    upr_bound = q3 + (1.5 * IQR)

    for i in data:
        if i < lwr_bound or i > upr_bound:
            outliers.append(i)

    return outliers

# Assuming 'data' is your DataFrame column
sample_outliers = detect_outliers_iqr(data['noise_level'])
print("Outliers from IQR method: ", sample_outliers)

#living conditions

outliers = []

def detect_outliers_iqr(data):
    # Convert data to numeric type
    data = np.asarray(data, dtype=np.float64)

    data = sorted(data)
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    IQR = q3 - q1
    lwr_bound = q1 - (1.5 * IQR)
    upr_bound = q3 + (1.5 * IQR)

    for i in data:
        if i < lwr_bound or i > upr_bound:
            outliers.append(i)

    return outliers

# Assuming 'data' is your DataFrame column
sample_outliers = detect_outliers_iqr(data['living_conditions'])
print("Outliers from IQR method: ", sample_outliers)

#study load

#living conditions

outliers = []

def detect_outliers_iqr(data):
    # Convert data to numeric type
    data = np.asarray(data, dtype=np.float64)

    data = sorted(data)
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    IQR = q3 - q1
    lwr_bound = q1 - (1.5 * IQR)
    upr_bound = q3 + (1.5 * IQR)

    for i in data:
        if i < lwr_bound or i > upr_bound:
            outliers.append(i)

    return outliers

# Assuming 'data' is your DataFrame column
sample_outliers = detect_outliers_iqr(data['study_load'])
print("Outliers from IQR method: ", sample_outliers)

from sklearn.model_selection import train_test_split
# Assuming 'data' is your DataFrame
X_columns = ['anxiety_level', 'self_esteem', 'mental_health_history',
              'depression', 'headache', 'blood_pressure', 'sleep_quality',
              'breathing_problem', 'noise_level', 'living_conditions', 'safety',
              'basic_needs', 'study_load', 'teacher_student_relationship',
              'future_career_concerns', 'social_support', 'peer_pressure',
              'extracurricular_activities', 'bullying']

Y_columns_regression = ['academic_performance']
Y_columns_classification = ['stress_level']

# Independent variables (features)
X = data[X_columns]

# Dependent variables (target variables)
Y_regression = data[Y_columns_regression]
Y_classification = data[Y_columns_classification]

# Train-test split
X_train_reg, X_test_reg, Y_train_reg, Y_test_reg = train_test_split(X, Y_regression, test_size=0.2, random_state=0)
X_train_cls, X_test_cls, Y_train_cls, Y_test_cls = train_test_split(X, Y_classification, test_size=0.2, random_state=0)

"""**FEATURE SELECTION**"""

from sklearn.feature_selection import SelectKBest, f_classif, f_regression
import numpy as np
import matplotlib.pyplot as plt

# Define your independent variables (X) and dependent variables (Y) for regression
X_regression = data[['anxiety_level', 'self_esteem', 'mental_health_history', 'depression', 'headache',
          'blood_pressure', 'sleep_quality', 'breathing_problem', 'noise_level',
          'living_conditions', 'safety', 'basic_needs', 'study_load',
          'teacher_student_relationship', 'future_career_concerns', 'social_support',
          'peer_pressure', 'extracurricular_activities', 'bullying']]
Y_regression = data['academic_performance']

# Perform feature selection using Fisher Score for regression
fs_regression = SelectKBest(score_func=f_regression, k='all')
fs_regression.fit(X_regression, Y_regression)

# Get the feature scores for regression
feature_scores_regression = fs_regression.scores_

# Define your independent variables (X) and dependent variables (Y) for classification
X_classification = data[['anxiety_level', 'self_esteem', 'mental_health_history', 'depression', 'headache',
          'blood_pressure', 'sleep_quality', 'breathing_problem', 'noise_level',
          'living_conditions', 'safety', 'basic_needs', 'study_load',
          'teacher_student_relationship', 'future_career_concerns', 'social_support',
          'peer_pressure', 'extracurricular_activities', 'bullying']]
Y_classification = data['stress_level']

# Perform feature selection using Fisher Score for classification
fs_classification = SelectKBest(score_func=f_classif, k='all')
fs_classification.fit(X_classification, Y_classification)

# Get the feature scores for classification
feature_scores_classification = fs_classification.scores_

# Combine feature scores for regression and classification
combined_feature_scores = feature_scores_regression + feature_scores_classification

# Sort the combined feature scores in descending order
sorted_indices = np.argsort(combined_feature_scores)[::-1]

# Extract the top 16 features
top_16_features = [X.columns[idx] for idx in sorted_indices[:16]]
top_16_scores = combined_feature_scores[sorted_indices[:16]]

# Plot the top 16 features and their scores
plt.figure(figsize=(10, 6))
plt.barh(top_16_features, top_16_scores, color='skyblue')
plt.xlabel('Fisher Score')
plt.ylabel('Feature')
plt.title('Top 16 Features by Fisher Score')
plt.gca().invert_yaxis()  # Invert y-axis to display the highest score at the top
plt.show()

"""# **HYPERPARAMETER TUNING ON REGRESSION**

**LINEAR REGRESSION**
"""

X_regression

Y_regression

X_selected_regression = X[top_16_features]
X_selected_regression

from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV

# Define the parameter grid for hyperparameter tuning
param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}

# Create a Ridge regression instance
ridge_regressor = Ridge()

# Create a GridSearchCV object
grid_search = GridSearchCV(estimator=ridge_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

# Perform hyperparameter tuning
grid_search.fit(X_selected_regression, Y_regression)

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Get the best model
best_model_linear = grid_search.best_estimator_

# Fit the best model to the data
best_model_linear.fit(X_selected_regression, Y_regression)

"""**RANDOM FOREST**"""

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Create a RandomForestRegressor instance
rf_regressor = RandomForestRegressor(random_state=0)

# Create a GridSearchCV object
grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

# Perform hyperparameter tuning
grid_search.fit(X_selected_regression, Y_regression)

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Get the best model
best_model_rf = grid_search.best_estimator_

# Fit the best model to the data
best_model_rf.fit(X_selected_regression, Y_regression)

"""# **HYPERPARAMETER TUNING ON CLASSIFICATION**

**LOGISTIC REGRESSION**
"""

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

# Define the hyperparameter grid for Logistic Regression
logistic_param_grid = {
    'penalty': ['l1', 'l2'],  # Regularization penalty ('l1' for Lasso, 'l2' for Ridge)
    'C': [0.001, 0.01, 0.1, 1, 10, 100]  # Inverse of regularization strength
}

# Instantiate the Logistic Regression classifier
logistic_reg = LogisticRegression(max_iter=1000, random_state=0)

# Instantiate the GridSearchCV object for Logistic Regression
logistic_grid_search = GridSearchCV(estimator=logistic_reg, param_grid=logistic_param_grid, cv=5, scoring='accuracy')

# Fit the grid search to the data
logistic_grid_search.fit(X_selected_regression, Y_classification)

# Get the best hyperparameters for Logistic Regression
best_logistic_hyperparams = logistic_grid_search.best_params_

# Print the best hyperparameters for Logistic Regression
print("Best Hyperparameters for Logistic Regression:", best_logistic_hyperparams)

# Print the best estimator for Logistic Regression
print(logistic_grid_search.best_estimator_)

"""**RANDOM FOREST**"""

from sklearn.ensemble import RandomForestClassifier

# Define the hyperparameter grid for Random Forest
rf_param_grid = {
    'n_estimators': [100, 150, 200],  # Number of trees in the forest
    'max_depth': [5, 10, 20],  # Maximum depth of the trees
    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node
    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be a leaf node
}

# Instantiate the Random Forest classifier
rf_classifier = RandomForestClassifier(random_state=0)

# Instantiate the GridSearchCV object for Random Forest
rf_grid_search = GridSearchCV(estimator=rf_classifier, param_grid=rf_param_grid, cv=5, scoring='accuracy')

# Fit the grid search to the data
rf_grid_search.fit(X_selected_regression, Y_classification)

# Get the best hyperparameters for Random Forest
best_rf_hyperparams = rf_grid_search.best_params_

# Print the best hyperparameters for Random Forest
print("Best Hyperparameters for Random Forest:", best_rf_hyperparams)

# Print the best estimator for Random Forest
print(rf_grid_search.best_estimator_)

"""**SVM CLASSIFICATION**"""

from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

# Define the hyperparameters grid for SVM
param_grid_svm = {
    'C': [0.1, 1, 10, 100],              # Regularization parameter
    'kernel': ['linear', 'rbf', 'poly'], # Kernel type
    'gamma': ['scale', 'auto'],          # Kernel coefficient (for 'rbf' and 'poly' kernels)
}

# Create the SVM classifier
svm_classifier = SVC()

# Perform grid search with 5-fold cross-validation for SVM
grid_search_svm = GridSearchCV(svm_classifier, param_grid_svm, cv=5, scoring='accuracy')

# Fit the grid search to the data for SVM
grid_search_svm.fit(X_selected_regression, Y_classification)

# Get the best hyperparameters for SVM
best_params_svm = grid_search_svm.best_params_
print("\nBest Hyperparameters for SVM:", best_params_svm)

# Get the best SVM classifier with the optimal hyperparameters
best_estimator_svm = grid_search_svm.best_estimator_
print(best_estimator_svm)

"""# **PERFORMANCE METRICS FOR REGRESSION**

**LOGISTIC REGRESSION**
"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Predict using the linear regression model
y_pred_linear = best_model_linear.predict(X_selected_regression)

# Calculate Mean Squared Error (MSE)
mse_linear = mean_squared_error(Y_regression, y_pred_linear)

# Calculate Root Mean Squared Error (RMSE)
rmse_linear = np.sqrt(mse_linear)

# Calculate Mean Absolute Error (MAE)
mae_linear = mean_absolute_error(Y_regression, y_pred_linear)

# Calculate R-squared (R2) Score
r2_linear = r2_score(Y_regression, y_pred_linear)

# Print the performance metrics for linear regression
print("Linear Regression Metrics:")
print("Mean Squared Error (MSE):", mse_linear)
print("Root Mean Squared Error (RMSE):", rmse_linear)
print("Mean Absolute Error (MAE):", mae_linear)
print("R-squared (R2) Score:", r2_linear)

"""**RANDOM FOREST**"""

# Predict using the random forest regression model
y_pred_rf = best_model_rf.predict(X_selected_regression)

# Calculate Mean Squared Error (MSE)
mse_rf = mean_squared_error(Y_regression, y_pred_rf)

# Calculate Root Mean Squared Error (RMSE)
rmse_rf = np.sqrt(mse_rf)

# Calculate Mean Absolute Error (MAE)
mae_rf = mean_absolute_error(Y_regression, y_pred_rf)

# Calculate R-squared (R2) Score
r2_rf = r2_score(Y_regression, y_pred_rf)

# Print the performance metrics for random forest regression
print("\nRandom Forest Regression Metrics:")
print("Mean Squared Error (MSE):", mse_rf)
print("Root Mean Squared Error (RMSE):", rmse_rf)
print("Mean Absolute Error (MAE):", mae_rf)
print("R-squared (R2) Score:", r2_rf)

"""# **PERFORMANCE METRICS FOR CLASSIFICATION**

**LOGISTIC REGRESSION**
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Predict using the best Logistic Regression model
logistic_pred = logistic_grid_search.best_estimator_.predict(X_selected_regression)

# Calculate accuracy
accuracy = accuracy_score(Y_classification, logistic_pred)

# Calculate precision
precision = precision_score(Y_classification, logistic_pred, average='weighted')

# Calculate recall
recall = recall_score(Y_classification, logistic_pred, average='weighted')

# Calculate F1 score
f1 = f1_score(Y_classification, logistic_pred, average='weighted')

# Print the performance metrics for Logistic Regression
print("Logistic Regression Performance Metrics:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

#help(precision_score)

"""**SVM CLASSIFIER**"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Predict the labels using the best SVM classifier
Y_pred_svm = best_estimator_svm.predict(X_selected_regression)

# Calculate accuracy
accuracy_svm = accuracy_score(Y_classification, Y_pred_svm)

# Calculate precision
precision_svm = precision_score(Y_classification, Y_pred_svm, average='weighted')

# Calculate recall
recall_svm = recall_score(Y_classification, Y_pred_svm, average='weighted')

# Calculate F1 score
f1_svm = f1_score(Y_classification, Y_pred_svm, average='weighted')

# Print the performance metrics for SVM
print("Performance Metrics for SVM:")
print("Accuracy:", accuracy_svm)
print("Precision:", precision_svm)
print("Recall:", recall_svm)
print("F1 Score:", f1_svm)

"""# **PREDICTION**

**Regression (predicting 'academic_performance')**
"""

#regression task to predict 'academic_performance'

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Define features and target variable for regression
x_columns = ['anxiety_level', 'self_esteem', 'mental_health_history', 'depression',
       'headache', 'blood_pressure', 'breathing_problem', 'noise_level',
       'living_conditions', 'basic_needs',
       'study_load', 'teacher_student_relationship', 'future_career_concerns',
       'social_support', 'peer_pressure', 'extracurricular_activities']
y_columns_regression = ['academic_performance']

x_reg = data[x_columns]
y_reg = data[y_columns_regression]

# Train-test split for regression
x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_reg, y_reg, test_size=0.2, random_state=0)

# Initialize and train the Linear Regression model
regression_model = LinearRegression()
regression_model.fit(x_train_reg, y_train_reg)

# Make predictions on the test set
y_pred_reg = regression_model.predict(x_test_reg)

# Evaluate the model
mse = mean_squared_error(y_test_reg, y_pred_reg)
r2 = r2_score(y_test_reg, y_pred_reg)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

#random forest regression task to predict 'academic_performance'

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Define features and target variable for regression
x_columns = ['safety', 'basic_needs', 'academic_performance', 'study_load',
       'teacher_student_relationship', 'future_career_concerns',
       'social_support', 'peer_pressure', 'extracurricular_activities',
       'bullying']

x_reg = data[x_columns]
y_reg = data[y_columns_regression]

# Train-test split for regression
x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_reg, y_reg, test_size=0.2, random_state=0)

# Initialize and train the Random Forest Regressor model
random_forest_model = RandomForestRegressor(n_estimators=110, random_state=0)
random_forest_model.fit(x_train_reg, y_train_reg.values.ravel())  # Use ravel() to convert y_train_reg to a 1D array

# Make predictions on the test set
y_pred_reg = random_forest_model.predict(x_test_reg)

# Evaluate the model
mse = mean_squared_error(y_test_reg, y_pred_reg)
r2 = r2_score(y_test_reg, y_pred_reg)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

#correlation between features
corr_plot = sns.heatmap(data.corr(),annot = True,linewidths=8 )
plt.title("Correlation plot")
plt.show()

"""**Classification (predicting 'stress_level')**"""
